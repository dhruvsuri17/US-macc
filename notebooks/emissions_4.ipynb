{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from ../data/raw/point/2022hc_cb6_22m/inputs/ptegu/egu_cems_2022_POINT_20240615_2022cems_stackfix2_23jul2024_v0.csv...\n",
      "Data loaded. Shape: (126465, 77)\n",
      "Processed 90811 emission points\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Code/US-macc/venv/lib/python3.13/site-packages/pandas/core/indexing.py:1714\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1713\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1716\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/US-macc/venv/lib/python3.13/site-packages/pandas/core/generic.py:4153\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4144\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4145\u001b[0m \u001b[38;5;124;03mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   4146\u001b[0m \u001b[38;5;124;03mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4151\u001b[0m \u001b[38;5;124;03mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   4152\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4153\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4154\u001b[0m \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/US-macc/venv/lib/python3.13/site-packages/pandas/core/generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[1;32m   4131\u001b[0m     )\n\u001b[0;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4135\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4140\u001b[0m )\n",
      "File \u001b[0;32m~/Code/US-macc/venv/lib/python3.13/site-packages/pandas/core/internals/managers.py:891\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    890\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[0;32m--> 891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_convert_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n",
      "File \u001b[0;32m~/Code/US-macc/venv/lib/python3.13/site-packages/pandas/core/indexers/utils.py:282\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n, verify)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indices\n",
      "\u001b[0;31mIndexError\u001b[0m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 230\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# Create a new GeoDataFrame with only power plants\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m power_plant_indices:\n\u001b[0;32m--> 230\u001b[0m     egu_emis \u001b[38;5;241m=\u001b[39m \u001b[43memis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpower_plant_indices\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiltered to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(egu_emis)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m power plant emission points\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Code/US-macc/venv/lib/python3.13/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/US-macc/venv/lib/python3.13/site-packages/pandas/core/indexing.py:1743\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1741\u001b[0m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_list_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1747\u001b[0m     key \u001b[38;5;241m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[0;32m~/Code/US-macc/venv/lib/python3.13/site-packages/pandas/core/indexing.py:1717\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1716\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n\u001b[0;32m-> 1717\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional indexers are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ================================\n",
    "# Process the FF10_POINT file for InMAP compatibility\n",
    "# ================================\n",
    "\n",
    "# Path to your FF10_POINT format file\n",
    "file_path = \"../data/raw/point/2022hc_cb6_22m/inputs/ptegu/egu_cems_2022_POINT_20240615_2022cems_stackfix2_23jul2024_v0.csv\"\n",
    "\n",
    "print(f\"Reading data from {file_path}...\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = Path(\"../data/processed\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Count number of header lines to skip\n",
    "with open(file_path, 'r') as f:\n",
    "    header_lines = 0\n",
    "    for line in f:\n",
    "        if line.startswith('#'):\n",
    "            header_lines += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "# Read the FF10_POINT file, skipping header comments\n",
    "df = pd.read_csv(file_path, skiprows=header_lines, low_memory=False)\n",
    "\n",
    "print(f\"Data loaded. Shape: {df.shape}\")\n",
    "\n",
    "# Initialize lists to hold the processed data\n",
    "VOC, NOx, NH3, SOx, PM2_5 = [], [], [], [], []\n",
    "height, diam, temp, velocity = [], [], [], []\n",
    "coords = []\n",
    "\n",
    "# Define pollutant classifications based on the provided list\n",
    "voc_pollutants = [\n",
    "    'VOC', \n",
    "    # Volatile organic compounds\n",
    "    '75092', '71432', '50000', '110543', '85018', '91203', '108883',\n",
    "    '86737', '91576', '206440', '129000', '107028', '75070', '75569',\n",
    "    '1330207', '106990', '100414', '108952', '106467', '60344', '67663',\n",
    "    '78591', '80626', '74839', '74873', '75003', '75150', '75252',\n",
    "    '77781', '92524', '98828', '98862', '100425', '100447', '106934',\n",
    "    '107062', '108054', '108907', '117817', '121142', '123386', '127184',\n",
    "    '1634044', '107131', '74884', '92875', '108101', '131113', '132649',\n",
    "    '56235', '71556', '75014', '78875', '87865', '95476', '75354', '79005',\n",
    "    '84742', '85449', '91225', '106423', '106445', '95487', '108383',\n",
    "    '108394', '75343', '120821', '88062', '91587', '57147', '107051',\n",
    "    '67561', '86748', '59892', '1319773', '189640', '91941', '77474',\n",
    "    '95807', 'HOURACT', '79016', '542756', '118741', '1336363', '192972'\n",
    "]\n",
    "\n",
    "nox_pollutants = [\n",
    "    'NOX', 'NO3', 'N590'\n",
    "]\n",
    "\n",
    "sox_pollutants = [\n",
    "    'SO2', 'SO4', '7783064'\n",
    "]\n",
    "\n",
    "nh3_pollutants = [\n",
    "    'NH3'\n",
    "]\n",
    "\n",
    "pm25_pollutants = [\n",
    "    'PM25-PRI', 'PM25-FIL', 'PMFINE', 'PM-CON', 'EC', 'OC'\n",
    "]\n",
    "\n",
    "# Create a dictionary for quick lookup\n",
    "pollutant_map = {}\n",
    "for poll in voc_pollutants:\n",
    "    pollutant_map[poll] = 'VOC'\n",
    "for poll in nox_pollutants:\n",
    "    pollutant_map[poll] = 'NOx'\n",
    "for poll in sox_pollutants:\n",
    "    pollutant_map[poll] = 'SOx'\n",
    "for poll in nh3_pollutants:\n",
    "    pollutant_map[poll] = 'NH3'\n",
    "for poll in pm25_pollutants:\n",
    "    pollutant_map[poll] = 'PM2_5'\n",
    "\n",
    "# Process each row of the FF10_POINT file\n",
    "for _, row in df.iterrows():\n",
    "    try:\n",
    "        # Get pollutant code and value\n",
    "        poll = str(row['poll']).upper() if 'poll' in row else \"\"\n",
    "        emis_value = row['ann_value'] if 'ann_value' in row else 0\n",
    "        \n",
    "        # Skip if no emissions value\n",
    "        if pd.isna(emis_value) or emis_value == '':\n",
    "            continue\n",
    "            \n",
    "        # Convert emissions value to float\n",
    "        emis_value = float(emis_value)\n",
    "        \n",
    "        # Get units and convert to short tons if needed\n",
    "        emis_units = row['emissions uom'] if 'emissions uom' in row else 'TON'\n",
    "        if emis_units == 'LB':\n",
    "            emis_value = emis_value / 2000  # Convert pounds to short tons\n",
    "            \n",
    "        # Determine pollutant category\n",
    "        poll_category = pollutant_map.get(poll)\n",
    "        \n",
    "        # Skip pollutants not in our mapping\n",
    "        if poll_category is None:\n",
    "            continue\n",
    "            \n",
    "        # Initialize emissions values\n",
    "        voc_val, nox_val, nh3_val, sox_val, pm25_val = 0, 0, 0, 0, 0\n",
    "        \n",
    "        # Set the appropriate value based on pollutant category\n",
    "        if poll_category == 'VOC':\n",
    "            voc_val = emis_value\n",
    "        elif poll_category == 'NOx':\n",
    "            nox_val = emis_value\n",
    "        elif poll_category == 'NH3':\n",
    "            nh3_val = emis_value\n",
    "        elif poll_category == 'SOx':\n",
    "            sox_val = emis_value\n",
    "        elif poll_category == 'PM2_5':\n",
    "            pm25_val = emis_value\n",
    "            \n",
    "        # Append emissions values to respective lists\n",
    "        VOC.append(voc_val)\n",
    "        NOx.append(nox_val)\n",
    "        NH3.append(nh3_val)\n",
    "        SOx.append(sox_val)\n",
    "        PM2_5.append(pm25_val)\n",
    "            \n",
    "        # Process stack parameters with unit conversions\n",
    "        # Height (convert to meters)\n",
    "        h = row['stkhgt'] if 'stkhgt' in row else ''\n",
    "        if h != '' and not pd.isna(h):\n",
    "            # Assuming height is in feet in the FF10_POINT file\n",
    "            height.append(float(h) * 0.3048)  # Convert feet to meters\n",
    "        else:\n",
    "            height.append(0)\n",
    "            \n",
    "        # Diameter (convert to meters)\n",
    "        d = row['stkdiam'] if 'stkdiam' in row else ''\n",
    "        if d != '' and not pd.isna(d):\n",
    "            # Assuming diameter is in feet in the FF10_POINT file\n",
    "            diam.append(float(d) * 0.3048)  # Convert feet to meters\n",
    "        else:\n",
    "            diam.append(0)\n",
    "            \n",
    "        # Temperature (convert to Kelvin)\n",
    "        t = row['stktemp'] if 'stktemp' in row else ''\n",
    "        if t != '' and not pd.isna(t):\n",
    "            # Assuming temperature is in Fahrenheit in the FF10_POINT file\n",
    "            temp.append((float(t) - 32) * 5.0/9.0 + 273.15)  # Convert F to K\n",
    "        else:\n",
    "            temp.append(0)\n",
    "            \n",
    "        # Velocity (convert to m/s)\n",
    "        v = row['stkvel'] if 'stkvel' in row else ''\n",
    "        if v != '' and not pd.isna(v):\n",
    "            # Assuming velocity is in feet/sec in the FF10_POINT file\n",
    "            velocity.append(float(v) * 0.3048)  # Convert ft/s to m/s\n",
    "        else:\n",
    "            velocity.append(0)\n",
    "            \n",
    "        # Get coordinates\n",
    "        lon = row['longitude'] if 'longitude' in row else None\n",
    "        lat = row['latitude'] if 'latitude' in row else None\n",
    "        \n",
    "        if lon is not None and lat is not None and not pd.isna(lon) and not pd.isna(lat):\n",
    "            coords.append(Point(float(lon), float(lat)))\n",
    "        else:\n",
    "            # Skip this record if coordinates are missing\n",
    "            VOC.pop()\n",
    "            NOx.pop()\n",
    "            NH3.pop()\n",
    "            SOx.pop()\n",
    "            PM2_5.pop()\n",
    "            height.pop()\n",
    "            diam.pop()\n",
    "            temp.pop()\n",
    "            velocity.pop()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Processed {len(coords)} emission points\")\n",
    "\n",
    "# Create the emissions GeoDataFrame in the exact format needed for InMAP\n",
    "emis = gpd.GeoDataFrame({\n",
    "    \"VOC\": VOC, \n",
    "    \"NOx\": NOx, \n",
    "    \"NH3\": NH3, \n",
    "    \"SOx\": SOx, \n",
    "    \"PM2_5\": PM2_5,\n",
    "    \"height\": height, \n",
    "    \"diam\": diam, \n",
    "    \"temp\": temp, \n",
    "    \"velocity\": velocity\n",
    "}, geometry=coords, crs='epsg:4269')\n",
    "\n",
    "# Filter out any rows with all zeros for emissions\n",
    "emis = emis[(emis['VOC'] > 0) | (emis['NOx'] > 0) | (emis['NH3'] > 0) | \n",
    "            (emis['SOx'] > 0) | (emis['PM2_5'] > 0)]\n",
    "\n",
    "# Filter for power plants only using NAICS code (if available in the original data)\n",
    "if 'naics' in df.columns:\n",
    "    # Create a mapping from coordinates to NAICS codes\n",
    "    coord_to_naics = {}\n",
    "    for _, row in df.iterrows():\n",
    "        if not pd.isna(row['longitude']) and not pd.isna(row['latitude']):\n",
    "            coord_key = (float(row['longitude']), float(row['latitude']))\n",
    "            if 'naics' in row and not pd.isna(row['naics']):\n",
    "                naics = str(row['naics'])\n",
    "                # If this is a power plant NAICS code\n",
    "                if naics.startswith('2211'):\n",
    "                    coord_to_naics[coord_key] = True\n",
    "    \n",
    "    # Filter emissions to only include power plants\n",
    "    power_plant_indices = []\n",
    "    for i, point in enumerate(coords):\n",
    "        coord_key = (point.x, point.y)\n",
    "        if coord_key in coord_to_naics:\n",
    "            power_plant_indices.append(i)\n",
    "    \n",
    "    # Create a new GeoDataFrame with only power plants\n",
    "    if power_plant_indices:\n",
    "        egu_emis = emis.iloc[power_plant_indices].copy()\n",
    "        print(f\"Filtered to {len(egu_emis)} power plant emission points\")\n",
    "    else:\n",
    "        egu_emis = emis.copy()\n",
    "        print(\"No power plants identified. Using all emission points.\")\n",
    "else:\n",
    "    egu_emis = emis.copy()\n",
    "    print(\"NAICS codes not found. Using all emission points.\")\n",
    "\n",
    "# ================================\n",
    "# Inspect and validate the emissions data\n",
    "# ================================\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nEmissions Summary (in short tons/year):\")\n",
    "emission_sums = egu_emis.sum(axis=0)[[\"VOC\", \"NOx\", \"NH3\", \"SOx\", \"PM2_5\"]]\n",
    "print(emission_sums)\n",
    "\n",
    "print(\"\\nStack Parameter Statistics:\")\n",
    "stack_stats = egu_emis[[\"height\", \"diam\", \"temp\", \"velocity\"]].describe()\n",
    "print(stack_stats)\n",
    "\n",
    "# Save the processed emissions data\n",
    "output_file = f\"{output_dir}/processed_emissions_for_inmap.gpkg\"\n",
    "egu_emis.to_file(output_file, driver=\"GPKG\")\n",
    "print(f\"\\nSaved processed emissions data to {output_file}\")\n",
    "\n",
    "# Return the processed emissions for use with the run_sr function\n",
    "print(\"\\nReady to use with run_sr function!\")\n",
    "print(\"Example: resultsISRM = run_sr(egu_emis, model='isrm', emis_units='tons/year')\")\n",
    "\n",
    "# The emissions GeoDataFrame is now in the exact format needed for InMAP\n",
    "egu_gdf = egu_emis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from ../data/raw/point/2022hc_cb6_22m/inputs/ptegu/egu_cems_2022_POINT_20240615_2022cems_stackfix2_23jul2024_v0.csv...\n",
      "Data loaded. Shape: (126465, 77)\n",
      "Processed 90811 emission points\n",
      "Filtered to 86671 emission points with non-zero emissions\n",
      "Filtered to 84806 power plant emission points using NAICS codes\n",
      "\n",
      "Emissions Summary (in short tons/year):\n",
      "VOC      3.322371e+10\n",
      "NOx      7.256522e+05\n",
      "NH3      1.373875e+04\n",
      "SOx      8.506148e+05\n",
      "PM2_5    2.303993e+05\n",
      "dtype: float64\n",
      "\n",
      "Stack Parameter Statistics:\n",
      "             height          diam          temp      velocity\n",
      "count  84806.000000  84806.000000  84806.000000  84806.000000\n",
      "mean      62.795411      4.974696    517.902599     25.233935\n",
      "std       61.025807      2.183049    213.628689     15.306950\n",
      "min        0.000000      0.000000      0.000000      0.000000\n",
      "25%       19.812000      3.657600    360.372222     17.007840\n",
      "50%       43.281600      5.181600    422.038889     21.336000\n",
      "75%       76.200000      6.096000    727.594444     31.811671\n",
      "max      316.382400     16.885920   1140.372222    210.424806\n",
      "\n",
      "Saved processed emissions data to ../data/processed/processed_emissions_for_inmap.gpkg\n",
      "\n",
      "Ready to use with run_sr function!\n",
      "Example: resultsISRM = run_sr(egu_emis, model='isrm', emis_units='tons/year')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ================================\n",
    "# Process the FF10_POINT file for InMAP compatibility\n",
    "# ================================\n",
    "\n",
    "# Path to your specific FF10_POINT format file\n",
    "file_path = \"../data/raw/point/2022hc_cb6_22m/inputs/ptegu/egu_cems_2022_POINT_20240615_2022cems_stackfix2_23jul2024_v0.csv\"\n",
    "\n",
    "print(f\"Reading data from {file_path}...\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = Path(\"../data/processed\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Count number of header lines to skip\n",
    "with open(file_path, 'r') as f:\n",
    "    header_lines = 0\n",
    "    for line in f:\n",
    "        if line.startswith('#'):\n",
    "            header_lines += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "# Read the FF10_POINT file, skipping header comments\n",
    "df = pd.read_csv(file_path, skiprows=header_lines, low_memory=False)\n",
    "\n",
    "print(f\"Data loaded. Shape: {df.shape}\")\n",
    "\n",
    "# Initialize lists to hold the processed data\n",
    "VOC, NOx, NH3, SOx, PM2_5 = [], [], [], [], []\n",
    "height, diam, temp, velocity = [], [], [], []\n",
    "coords = []\n",
    "naics_codes = []  # Track NAICS codes for each emission point\n",
    "\n",
    "# Define pollutant classifications based on the provided list\n",
    "voc_pollutants = [\n",
    "    'VOC', \n",
    "    # Volatile organic compounds\n",
    "    '75092', '71432', '50000', '110543', '85018', '91203', '108883',\n",
    "    '86737', '91576', '206440', '129000', '107028', '75070', '75569',\n",
    "    '1330207', '106990', '100414', '108952', '106467', '60344', '67663',\n",
    "    '78591', '80626', '74839', '74873', '75003', '75150', '75252',\n",
    "    '77781', '92524', '98828', '98862', '100425', '100447', '106934',\n",
    "    '107062', '108054', '108907', '117817', '121142', '123386', '127184',\n",
    "    '1634044', '107131', '74884', '92875', '108101', '131113', '132649',\n",
    "    '56235', '71556', '75014', '78875', '87865', '95476', '75354', '79005',\n",
    "    '84742', '85449', '91225', '106423', '106445', '95487', '108383',\n",
    "    '108394', '75343', '120821', '88062', '91587', '57147', '107051',\n",
    "    '67561', '86748', '59892', '1319773', '189640', '91941', '77474',\n",
    "    '95807', 'HOURACT', '79016', '542756', '118741', '1336363', '192972'\n",
    "]\n",
    "\n",
    "nox_pollutants = [\n",
    "    'NOX', 'NO3', 'N590'\n",
    "]\n",
    "\n",
    "sox_pollutants = [\n",
    "    'SO2', 'SO4', '7783064'\n",
    "]\n",
    "\n",
    "nh3_pollutants = [\n",
    "    'NH3'\n",
    "]\n",
    "\n",
    "pm25_pollutants = [\n",
    "    'PM25-PRI', 'PM25-FIL', 'PMFINE', 'PM-CON', 'EC', 'OC'\n",
    "]\n",
    "\n",
    "# Create a dictionary for quick lookup\n",
    "pollutant_map = {}\n",
    "for poll in voc_pollutants:\n",
    "    pollutant_map[poll] = 'VOC'\n",
    "for poll in nox_pollutants:\n",
    "    pollutant_map[poll] = 'NOx'\n",
    "for poll in sox_pollutants:\n",
    "    pollutant_map[poll] = 'SOx'\n",
    "for poll in nh3_pollutants:\n",
    "    pollutant_map[poll] = 'NH3'\n",
    "for poll in pm25_pollutants:\n",
    "    pollutant_map[poll] = 'PM2_5'\n",
    "\n",
    "# Process each row of the FF10_POINT file\n",
    "for _, row in df.iterrows():\n",
    "    try:\n",
    "        # Get pollutant code and value\n",
    "        poll = str(row['poll']).upper() if 'poll' in row else \"\"\n",
    "        emis_value = row['ann_value'] if 'ann_value' in row else 0\n",
    "        \n",
    "        # Skip if no emissions value\n",
    "        if pd.isna(emis_value) or emis_value == '':\n",
    "            continue\n",
    "            \n",
    "        # Convert emissions value to float\n",
    "        emis_value = float(emis_value)\n",
    "        \n",
    "        # Get units and convert to short tons if needed\n",
    "        emis_units = row['emissions uom'] if 'emissions uom' in row else 'TON'\n",
    "        if emis_units == 'LB':\n",
    "            emis_value = emis_value / 2000  # Convert pounds to short tons\n",
    "            \n",
    "        # Determine pollutant category\n",
    "        poll_category = pollutant_map.get(poll)\n",
    "        \n",
    "        # Skip pollutants not in our mapping\n",
    "        if poll_category is None:\n",
    "            continue\n",
    "            \n",
    "        # Initialize emissions values\n",
    "        voc_val, nox_val, nh3_val, sox_val, pm25_val = 0, 0, 0, 0, 0\n",
    "        \n",
    "        # Set the appropriate value based on pollutant category\n",
    "        if poll_category == 'VOC':\n",
    "            voc_val = emis_value\n",
    "        elif poll_category == 'NOx':\n",
    "            nox_val = emis_value\n",
    "        elif poll_category == 'NH3':\n",
    "            nh3_val = emis_value\n",
    "        elif poll_category == 'SOx':\n",
    "            sox_val = emis_value\n",
    "        elif poll_category == 'PM2_5':\n",
    "            pm25_val = emis_value\n",
    "        \n",
    "        # Get coordinates\n",
    "        lon = row['longitude'] if 'longitude' in row else None\n",
    "        lat = row['latitude'] if 'latitude' in row else None\n",
    "        \n",
    "        if lon is None or lat is None or pd.isna(lon) or pd.isna(lat):\n",
    "            continue  # Skip records without valid coordinates\n",
    "            \n",
    "        # Process stack parameters with unit conversions\n",
    "        # Height (convert to meters)\n",
    "        h = row['stkhgt'] if 'stkhgt' in row else ''\n",
    "        if h != '' and not pd.isna(h):\n",
    "            # Assuming height is in feet in the FF10_POINT file\n",
    "            h_val = float(h) * 0.3048  # Convert feet to meters\n",
    "        else:\n",
    "            h_val = 0\n",
    "            \n",
    "        # Diameter (convert to meters)\n",
    "        d = row['stkdiam'] if 'stkdiam' in row else ''\n",
    "        if d != '' and not pd.isna(d):\n",
    "            # Assuming diameter is in feet in the FF10_POINT file\n",
    "            d_val = float(d) * 0.3048  # Convert feet to meters\n",
    "        else:\n",
    "            d_val = 0\n",
    "            \n",
    "        # Temperature (convert to Kelvin)\n",
    "        t = row['stktemp'] if 'stktemp' in row else ''\n",
    "        if t != '' and not pd.isna(t):\n",
    "            # Assuming temperature is in Fahrenheit in the FF10_POINT file\n",
    "            t_val = (float(t) - 32) * 5.0/9.0 + 273.15  # Convert F to K\n",
    "        else:\n",
    "            t_val = 0\n",
    "            \n",
    "        # Velocity (convert to m/s)\n",
    "        v = row['stkvel'] if 'stkvel' in row else ''\n",
    "        if v != '' and not pd.isna(v):\n",
    "            # Assuming velocity is in feet/sec in the FF10_POINT file\n",
    "            v_val = float(v) * 0.3048  # Convert ft/s to m/s\n",
    "        else:\n",
    "            v_val = 0\n",
    "        \n",
    "        # Get NAICS code if available\n",
    "        naics = row['naics'] if 'naics' in row else None\n",
    "        \n",
    "        # Add to our data lists\n",
    "        coords.append(Point(float(lon), float(lat)))\n",
    "        VOC.append(voc_val)\n",
    "        NOx.append(nox_val)\n",
    "        NH3.append(nh3_val)\n",
    "        SOx.append(sox_val)\n",
    "        PM2_5.append(pm25_val)\n",
    "        height.append(h_val)\n",
    "        diam.append(d_val)\n",
    "        temp.append(t_val)\n",
    "        velocity.append(v_val)\n",
    "        naics_codes.append(str(naics) if naics is not None and not pd.isna(naics) else '')\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Processed {len(coords)} emission points\")\n",
    "\n",
    "# Create the emissions GeoDataFrame in the exact format needed for InMAP\n",
    "data_dict = {\n",
    "    \"VOC\": VOC, \n",
    "    \"NOx\": NOx, \n",
    "    \"NH3\": NH3, \n",
    "    \"SOx\": SOx, \n",
    "    \"PM2_5\": PM2_5,\n",
    "    \"height\": height, \n",
    "    \"diam\": diam, \n",
    "    \"temp\": temp, \n",
    "    \"velocity\": velocity,\n",
    "    \"naics_code\": naics_codes\n",
    "}\n",
    "\n",
    "emis = gpd.GeoDataFrame(data_dict, geometry=coords, crs='epsg:4269')\n",
    "\n",
    "# Filter out any rows with all zeros for emissions\n",
    "emis = emis[(emis['VOC'] > 0) | (emis['NOx'] > 0) | (emis['NH3'] > 0) | \n",
    "            (emis['SOx'] > 0) | (emis['PM2_5'] > 0)]\n",
    "\n",
    "print(f\"Filtered to {len(emis)} emission points with non-zero emissions\")\n",
    "\n",
    "# ================================\n",
    "# Filter for power plants\n",
    "# ================================\n",
    "\n",
    "# This is already EGU CEMS data (Electricity Generating Units Continuous Emissions Monitoring System)\n",
    "# So all emissions should be from power plants, but we'll check NAICS codes if available\n",
    "egu_naics_prefixes = ['2211', '221111', '221112', '221113', '221114', '221115', \n",
    "                      '221116', '221117', '221118', '221121', '221122']\n",
    "\n",
    "# Create a mask for power plants\n",
    "is_power_plant = emis['naics_code'].apply(\n",
    "    lambda x: any(str(x).startswith(prefix) for prefix in egu_naics_prefixes) \n",
    "              if x else False\n",
    ")\n",
    "\n",
    "# Apply the mask to filter for power plants if NAICS codes are available and identified\n",
    "if is_power_plant.any():\n",
    "    egu_emis = emis[is_power_plant].copy()\n",
    "    print(f\"Filtered to {len(egu_emis)} power plant emission points using NAICS codes\")\n",
    "else:\n",
    "    # Since this is EGU CEMS data, we can use all points even without NAICS codes\n",
    "    print(\"Using all emission points (dataset is already for power plants - EGU CEMS)\")\n",
    "    egu_emis = emis.copy()\n",
    "\n",
    "# ================================\n",
    "# Clean the data for InMAP compatibility\n",
    "# ================================\n",
    "\n",
    "# Drop the NAICS column as it's not needed for InMAP\n",
    "if 'naics_code' in egu_emis.columns:\n",
    "    egu_emis = egu_emis.drop(columns=['naics_code'])\n",
    "\n",
    "# ================================\n",
    "# Inspect and validate the emissions data\n",
    "# ================================\n",
    "\n",
    "# Display summary statistics - properly handle the geometry column\n",
    "print(\"\\nEmissions Summary (in short tons/year):\")\n",
    "# Convert to DataFrame to exclude geometry column for sum operation\n",
    "emissions_df = pd.DataFrame(egu_emis.drop(columns=['geometry']))\n",
    "emission_sums = emissions_df[[\"VOC\", \"NOx\", \"NH3\", \"SOx\", \"PM2_5\"]].sum()\n",
    "print(emission_sums)\n",
    "\n",
    "print(\"\\nStack Parameter Statistics:\")\n",
    "stack_stats = emissions_df[[\"height\", \"diam\", \"temp\", \"velocity\"]].describe()\n",
    "print(stack_stats)\n",
    "\n",
    "# Save the processed emissions data\n",
    "output_file = f\"{output_dir}/processed_emissions_for_inmap.gpkg\"\n",
    "egu_emis.to_file(output_file, driver=\"GPKG\")\n",
    "print(f\"\\nSaved processed emissions data to {output_file}\")\n",
    "\n",
    "# Return the processed emissions for use with the run_sr function\n",
    "print(\"\\nReady to use with run_sr function!\")\n",
    "print(\"Example: resultsISRM = run_sr(egu_emis, model='isrm', emis_units='tons/year')\")\n",
    "\n",
    "# The emissions GeoDataFrame is now in the exact format needed for InMAP\n",
    "egu_gdf = egu_emis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_cems = pd.read_csv('../data/2023_annual_emissions_CEMS.csv')\n",
    "plants = emissions_cems['Facility ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     3,      9,     10, ..., 880108, 880109, 880110], shape=(1343,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plants = df['Facility ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
